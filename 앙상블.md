# 앙상블 기법

> 여러 개의 분류 모델을 조합해서 더 나은 성능을 내는 방법

## 1. 배깅(bagging)

> 한 가지 분류 모델을 여러 개 만들어서 서로 다른 학습 데이터로 학습시킨 후( **부트스트랩**), 동일한 테스트 데이터에 대한 서로 다른 예측값들을 투표를 통해(**어그리게이팅**) 가장 높은 예측값으로 최종 결론을 내리는 앙상블 기법

==> 과대적합이 쉬운 모델에 상당히 적합한 앙상블 

- **부트스트랩(bootstrap)**

  > 데이터를 조금은 편향되도록 샘플링하는 기법

  - 데이터 샘플링 시 편향을 높임으로써 분산이 높은 모델의 과대적합 위험을 줄이는 효과를 준다.

  - N개의 데이터를 총  k개의 데이터로 나누어 담을 때 중복을 허용해서 데이터의 편향을 높인다. 

    ( 부트스트랩을 사용하지 않으면 모두 동일하게 N개의 데이터로 학습 => 동일한 분류모델을 가진다.)

    

    **ex)** 전체 데이터 : [1,2,3,4,5,6,7,8,9]

    ====>의사 결정 트리 6개를 배깅할 경우, 부트스트랩의 결과

    - 트리1의 학습 데이터 : [1,2,3,4,5,1]

    - 트리2의 학습 데이터 : [2,3,4,5,6,2]

    - 트리3의 학습 데이터 : [3,4,5,6,7,3]

    - ...

    - 트리6의 학습 데이터 : [6,7,8,9,1,6]

      

- **어그리게이팅(aggregating)**

  > 여러 분류 모델이 예측한 값들을 조합해서 하나의 결론을 도출하는 과정(결론 : 투표를 통해 결정)

  - **하드 보팅** (투표와 비슷) : 배깅에 포함된 k개의 분류 모델에서 최대 득표를 받은 예측값으로 결론을 도출

  - **소프트 보팅** ( 하드 보팅보다 더 정교한 투표 방식)

    |                          하드 보팅                           |                         소프트 보팅                          |
    | :----------------------------------------------------------: | :----------------------------------------------------------: |
    | 각 분류 모델은 최고의 확률을 갖는 분류값만 어그리게이팅할 때 리턴 |                  모든 분류값의 확률을 리턴                   |
    |          단순히 가장 많은 투표를 받은 분류값을 도출          | 각 분류값별 확률을 더해준 값을 점수로 사용해 최대 점수를 가진 분류값을 도출 |
    | <img src="/image/1.png" style="zoom:60%;" />   === 1로 예측  |   <img src="/image/2.png" style="zoom:60%;" /> ===1로 예측   |

- **랜덤 포레스트**

  > 여러 의사결정 트리를 배깅해서 예측을 실행하는 모델

  - 각 노드에 주어진 데이터를 샘플링해서 일부 데이터를 제외한 채 최적의 특징을 찾아 트리를 분기한다.
  - 과대적합되기 쉬운 의사결정 트리에 적용하면 과대적합을 줄여 성능을 높일 수 있다.

## 2. 부스팅(boosting)

> (여러 개의 분류기를 만들어 투표를 통해 예측값을 결정하는 것은 배깅과 동일)
>
> - 배깅 : 서로 다른 알고리즘에 기반한 여러 분류기를 병렬적으로 학습
> - **부스팅** : 동일한 알고리즘의 분류기를 **순차적으로 학습**해서 여러 개의 분류기를 만든 후, 테스트할 때 **가중 투표**를 통해 예측값을 결정 

- **순차적 학습**

  > 첫 번째 의사결정트리의 테스트 결과에 따라 학습 데이터를 보강해서 두 번째 의사결정 트리를 학습한다.
  >
  > 이처럼 **순차적으로 학습 데이터를 보강하며 동일한 알고리즘의 분류기를 여러 개 만드는 과정**을 가진다.

- **가중 투표**

  |        | 분류기1 | 분류기2 | 분류기3 |
  | :----: | :-----: | :-----: | :-----: |
  | 정확도 |   0.4   |   0.5   |  0.95   |

  - **하드 보팅**일 경우 : 

    |        | 분류기1 | 분류기2 | 분류기3 |
    | :----: | :-----: | :-----: | :-----: |
    | 분류값 | 오렌지  | 오렌지  |  키위   |

    - 오렌지 : 0.4 + 0.5

    - 키위 : 0.95

      ==>두 분류기가 오렌지로 예측했지만 가중 투표 결과, 키위로 분류한다.

    

  - **소프트 보팅**일 경우 :

    |        |         분류기1          |         분류기2          |         분류기3          |
    | :----: | :----------------------: | :----------------------: | :----------------------: |
    | 분류값 | 오렌지 : 0.7, 키위 : 0.3 | 오렌지 : 0.8, 키위 : 0.2 | 오렌지 : 0.1, 키위 : 0.9 |

    - 오렌지 : 0.4 0.7 + 0.5 0.8 + 0.95 0.1 = 0.775

    - 키위 : 0.4 0.3 + 0.5 0.2 + 0.95 0.9 = 1.075

      ====> 키위로 분류한다.